{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nech-C/comp5300-project/blob/main/5530project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p34CaXtZJeH8",
        "outputId": "ede14bbd-c405-4a11-b687-62eff609e58b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/GQA\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "path = \"/content/drive/My Drive/GQA/\"\n",
        "\n",
        "# import lib\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import shutil\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "# Replace 'My Drive' with the specific path where you want to save the files in your Drive if needed\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "%cd \"$path\"\n",
        "\n",
        "!git -C \"/content/drive/My Drive/GQA/comp5300-project\" pull\n",
        "\n",
        "sys.path.append(os.path.join(path, \"comp5300-project\"))\n",
        "from utils.dataset_processing import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5JlwI3_I5Ya",
        "outputId": "2004661f-a238-435e-844b-dbeb9f6c3be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/gqa/images': No such file or directory\n",
            "cp: cannot create regular file '/content/gqa/questions': No such file or directory\n",
            "cp: cannot create regular file '/content/gqa/sceneGraphs': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# constants - google drive\n",
        "SCRIPT_PATH = \"/content/drive/MyDrive/GQA/comp5300-project\"\n",
        "IMAGE_ZIP = '/content/drive/MyDrive/GQA/images.zip'\n",
        "QUESTIONS_ZIP = '/content/drive/MyDrive/GQA/questions.zip'\n",
        "SCENE_GRAPHS_ZIP = '/content/drive/MyDrive/GQA/sceneGraphs.zip'\n",
        "\n",
        "# constants - vm\n",
        "BASE = '/content/gqa'\n",
        "\n",
        "!cp $IMAGE_ZIP $BASE/images\n",
        "!cp $QUESTIONS_ZIP $BASE/questions\n",
        "!cp $SCENE_GRAPHS_ZIP $BASE/sceneGraphs\n",
        "# create dirs and unzip those in BASE\n",
        "!mkdir -p $BASE/images\n",
        "!mkdir -p $BASE/questions\n",
        "!mkdir -p $BASE/sceneGraphs\n",
        "!unzip -q $QUESTIONS_ZIP -d $BASE/questions\n",
        "!unzip -q $SCENE_GRAPHS_ZIP -d $BASE/sceneGraphs\n",
        "!unzip -q $IMAGE_ZIP -d $BASE/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tUvl4zmFkB9",
        "outputId": "1c6a1a9d-8cc9-42d9-ed29-e4c203a74e78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of files in images.zip: 148855\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "IMAGE_ZIP = '/content/drive/MyDrive/GQA/images.zip'\n",
        "\n",
        "with zipfile.ZipFile(IMAGE_ZIP, 'r') as zip_file:\n",
        "    num_files = len(zip_file.namelist())\n",
        "\n",
        "print(f\"Number of files in images.zip: {num_files}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zh__RZgcBY-G",
        "outputId": "e721b5b3-dcc3-4e13-8f56-aeebabf7062b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing completed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "TRAIN_ALL_QUESTIONS = \"/content/gqa/questions/train_all_questions\"\n",
        "IMAGES = \"/content/gqa/images/images\"\n",
        "PROCESSED_QUESTIONS = \"/content/drive/MyDrive/GQA/processed_questions\"\n",
        "\n",
        "# Create the processed_questions directory if it doesn't exist\n",
        "os.makedirs(PROCESSED_QUESTIONS, exist_ok=True)\n",
        "\n",
        "# Get a list of all the image names in the images directory\n",
        "image_names = set(os.listdir(IMAGES))\n",
        "\n",
        "# Get a list of all the JSON files in the train_all_questions directory\n",
        "json_files = [f for f in os.listdir(TRAIN_ALL_QUESTIONS) if f.endswith('.json')]\n",
        "\n",
        "for json_file in json_files:\n",
        "    json_path = os.path.join(TRAIN_ALL_QUESTIONS, json_file)\n",
        "\n",
        "    with open(json_path, 'r') as f:\n",
        "        questions_data = json.load(f)\n",
        "\n",
        "    processed_questions = {}\n",
        "\n",
        "    for question_id, question_info in questions_data.items():\n",
        "        image_id = question_info['imageId']\n",
        "        image_name = image_id + '.jpg'\n",
        "\n",
        "        # Check if the image exists in the set of image names\n",
        "        if image_name in image_names:\n",
        "            processed_question = {\n",
        "                'imageId': image_id,\n",
        "                'question': question_info['question'],\n",
        "                'answer': question_info['answer'],\n",
        "                'fullAnswer': question_info['fullAnswer'],\n",
        "                'groups': question_info['groups']\n",
        "            }\n",
        "            processed_questions[question_id] = processed_question\n",
        "    # Save the processed questions to a new JSON file\n",
        "    processed_json_path = os.path.join(PROCESSED_QUESTIONS, json_file)\n",
        "    with open(processed_json_path, 'w') as f:\n",
        "        json.dump(processed_questions, f, indent=2)\n",
        "\n",
        "print(\"Processing completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create trainable .jsons\n",
        "processed_json_files = [os.path.join(PROCESSED_QUESTIONS, f) for f in os.listdir(PROCESSED_QUESTIONS) if f.endswith('.json')]\n",
        "trainable_save_path = \"/content/drive/MyDrive/GQA/trainable_questions\"\n",
        "os.makedirs(trainable_save_path, exist_ok=True)\n",
        "\n",
        "for json_file in processed_json_files:\n",
        "    with open(json_file, 'r') as f:\n",
        "        questions_data = json.load(f)\n",
        "\n",
        "        # generate trainable .json\n",
        "        trainable_questions = []\n",
        "        for question_id, question_info in questions_data.items():\n",
        "            image_name = question_info['imageId'] + '.jpg'\n",
        "\n",
        "            trainable_question = {\n",
        "              'id': question_id,\n",
        "              'image': image_name,\n",
        "              \"conversation\": [\n",
        "                  {\n",
        "                      \"from\": \"human\",\n",
        "                      \"value\": question_info['question']\n",
        "                  },\n",
        "                  {\n",
        "                      \"from\": \"gpt\",\n",
        "                      \"value\": question_info['answer']\n",
        "                  }\n",
        "              ],\n",
        "            }\n",
        "            trainable_questions.append(trainable_question)\n",
        "            # end of for\n",
        "\n",
        "        trainable_json_path = os.path.join(\n",
        "            trainable_save_path,\n",
        "            os.path.splitext(os.path.basename(json_file))[0] + \"_trainable.json\")\n",
        "\n",
        "        with open(trainable_json_path, 'w') as f:\n",
        "            json.dump(trainable_questions, f, indent=2)\n",
        "\n",
        "print(\"Processing completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h_oeMkc8Azv",
        "outputId": "3945cb48-70c3-4e7a-b46f-72fc47b29480"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepspeed\n",
        "!git lfs install\n",
        "!git clone https://huggingface.co/liuhaotian/llava-v1.6-mistral-7b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnGw4Cr_PMNk",
        "outputId": "09f10e0b-2216-4821-b116-7c35414a4bfc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepspeed in /usr/local/lib/python3.10/dist-packages (0.14.0)\n",
            "Requirement already satisfied: hjson in /usr/local/lib/python3.10/dist-packages (from deepspeed) (3.1.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.11.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.6.4)\n",
            "Requirement already satisfied: pynvml in /usr/local/lib/python3.10/dist-packages (from deepspeed) (11.5.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyOXGgNAe5ZGgF708cE7M4jf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}